{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNHT2Jaoe5_G",
        "outputId": "0846d44d-f909-4139-dfa5-029a4e6cd300"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2 pdfplumber pytesseract opencv-python pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYE96fjTeEbf",
        "outputId": "2049531e-075e-4d71-9842-2e02678a9f03"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (10.4.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nm3FTDT3dtww"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "from typing import List, Dict\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import re\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract"
      ],
      "metadata": {
        "id": "bzTXxB4md-A5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() + \"\\n\" if page.extract_text() else \"\"\n",
        "    return text"
      ],
      "metadata": {
        "id": "JjfZVPx_dx5O"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_scanned_pdf(file_path):\n",
        "    images = convert_from_path(file_path)\n",
        "    text = \"\"\n",
        "    for image in images:\n",
        "        text += pytesseract.image_to_string(image) + \"\\n\"\n",
        "    return text"
      ],
      "metadata": {
        "id": "duo2WoXUdx2k"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(file_path):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        try:\n",
        "            if pdfplumber.open(f).pages[0].extract_text():\n",
        "                return extract_text_from_pdf(file_path)\n",
        "            else:\n",
        "                return extract_text_from_scanned_pdf(file_path)\n",
        "        except:\n",
        "            return extract_text_from_scanned_pdf(file_path)"
      ],
      "metadata": {
        "id": "pIMcgtIfdx0G"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_between(text: str, start: str, end: str) -> str:\n",
        "    pattern = f'{re.escape(start)}(.*?){re.escape(end)}'\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "    return match.group(1).strip() if match else ''"
      ],
      "metadata": {
        "id": "aLU0RzQZJ96t"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_invoice_data(text: str) -> Dict[str, str]:\n",
        "    patterns = {\n",
        "        'invoice_number': r'Invoice #:\\s*(INV-\\d+)',\n",
        "        'invoice_date': r'Invoice Date:\\s*(\\d{2}\\s+\\w{3}\\s+\\d{4})',\n",
        "        'due_date': r'Due Date:\\s*(\\d{2}\\s+\\w{3}\\s+\\d{4})',\n",
        "        'gstin': r'GSTIN\\s*(\\S+)',\n",
        "        'mobile': r'Mobile\\s*(\\+?\\d[\\d\\s-]{10,})',\n",
        "        'email': r'Email\\s*(\\S+@\\S+)',\n",
        "        'customer_name': None,  # Will be extracted separately\n",
        "        'place_of_supply': None,  # Will be extracted separately\n",
        "        'total_amount': r'Total\\s*₹([\\d,.]+)',\n",
        "        'total_discount': r'Total Discount\\s*₹([\\d,.]+)',\n",
        "        'total_items_qty': r'Total Items / Qty\\s*:\\s*([\\d.]+\\s*/\\s*[\\d.]+)',\n",
        "        'amount_in_words': None,  # Will be extracted separately\n",
        "        'bank_name': None,  # Will be extracted separately\n",
        "        'account_number': r'Account #:\\s*(\\d+)',\n",
        "        'ifsc_code': r'IFSC Code:\\s*(\\S+)',\n",
        "        'branch': None,  # Will be extracted separately\n",
        "    }\n",
        "\n",
        "    data = {}\n",
        "    for key, pattern in patterns.items():\n",
        "        if pattern is None:\n",
        "            continue\n",
        "        match = re.search(pattern, text, re.MULTILINE | re.DOTALL)\n",
        "        if match:\n",
        "            data[key] = match.group(1).strip()\n",
        "\n",
        "    # Targeted extraction for problematic fields\n",
        "    data['customer_name'] = extract_between(text, 'Customer Details:', 'Place of Supply:')\n",
        "    data['place_of_supply'] = extract_between(text, 'Place of Supply:', '# Item')\n",
        "    data['amount_in_words'] = extract_between(text, 'Total amount (in words):', 'Amount Paid')\n",
        "    data['bank_name'] = extract_between(text, 'Bank:', 'Account #:')\n",
        "    data['branch'] = extract_between(text, 'Branch:', 'Authorized Signatory')\n",
        "\n",
        "    # Ensure original order of columns\n",
        "    ordered_data = {key: data.get(key, '') for key in patterns.keys()}\n",
        "    return ordered_data"
      ],
      "metadata": {
        "id": "hzuC4i2LJ7uG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_item_data(text: str) -> List[Dict[str, str]]:\n",
        "    item_section = re.search(r'# Item Rate / Item Qty Taxable Value Tax Amount Amount(.*?)Taxable Amount', text, re.DOTALL)\n",
        "    if not item_section:\n",
        "        return []\n",
        "\n",
        "    item_lines = item_section.group(1).strip().split('\\n')\n",
        "    items = []\n",
        "    i = 0\n",
        "    while i < len(item_lines):\n",
        "        if len(item_lines) - i >= 2:  # Ensure we have at least two lines to process\n",
        "            line1 = item_lines[i].strip()\n",
        "            line2 = item_lines[i+1].strip()\n",
        "\n",
        "            # Extract information from the two lines\n",
        "            match = re.match(r'(.*?)\\s+([\\d.]+)\\s+(\\d+)\\s+(\\d+\\s+\\w+)\\s+([\\d.]+)\\s+([\\d.]+\\s+\\(\\d+%\\))\\s+([\\d.]+)$', line1)\n",
        "            if match:\n",
        "                name = match.group(1)\n",
        "                rate = match.group(2)\n",
        "                qty = match.group(3)\n",
        "                qty_unit = match.group(4)\n",
        "                taxable_value = match.group(5)\n",
        "                tax_amount = match.group(6)\n",
        "                amount = match.group(7)\n",
        "\n",
        "                # Process the second line for discount and possible name continuation\n",
        "                discount_match = re.search(r'(.*?)\\s+([\\d.]+)\\s+\\(([-\\d.]+)%\\)$', line2)\n",
        "                if discount_match:\n",
        "                    name_continuation = discount_match.group(1).strip()\n",
        "                    original_rate = discount_match.group(2)\n",
        "                    discount = discount_match.group(3)\n",
        "\n",
        "                    # If there's a name continuation, add it to the name\n",
        "                    if name_continuation:\n",
        "                        name += ' ' + name_continuation\n",
        "\n",
        "                item = {\n",
        "                    'name': name,\n",
        "                    'rate': rate,\n",
        "                    'original_rate': original_rate,\n",
        "                    'discount': discount,\n",
        "                    'qty': qty,\n",
        "                    'qty_unit': qty_unit,\n",
        "                    'taxable_value': taxable_value,\n",
        "                    'tax_amount': tax_amount,\n",
        "                    'amount': amount\n",
        "                }\n",
        "                items.append(item)\n",
        "\n",
        "            i += 2  # Move to the next item (skip the processed second line)\n",
        "        else:\n",
        "            i += 1  # Move to the next line if we don't have a pair\n",
        "\n",
        "    return items"
      ],
      "metadata": {
        "id": "66_NCptZKBlM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_invoice(text: str, invoice_csv: str, items_csv: str):\n",
        "    invoice_data = extract_invoice_data(text)\n",
        "    item_data = extract_item_data(text)\n",
        "    print(item_data)\n",
        "\n",
        "    with open(invoice_csv, 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=invoice_data.keys())\n",
        "        writer.writeheader()\n",
        "        writer.writerow(invoice_data)\n",
        "\n",
        "    if item_data:\n",
        "        with open(items_csv, 'w', newline='', encoding='utf-8') as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=item_data[0].keys())\n",
        "            writer.writeheader()\n",
        "            writer.writerows(item_data)"
      ],
      "metadata": {
        "id": "Hi3sDopTKEkE"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_invoice(file_path):\n",
        "    extracted_text = extract_text(file_path)\n",
        "    process_invoice(extracted_text, 'invoice_data.csv', 'item_data.csv')"
      ],
      "metadata": {
        "id": "9O4B8kZPKEcJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/Jan to Mar/INV-150_Bhusan Naresh.pdf'\n",
        "pattern = os.path.join(folder_path, \"*.pdf\")\n",
        "\n",
        "for pdf in glob.glob(pattern):\n",
        "  extract_invoice(pdf)"
      ],
      "metadata": {
        "id": "6Yg7SvHiKfs3"
      },
      "execution_count": 44,
      "outputs": []
    }
  ]
}